# close ai documentation
This guide outlines how to run a code-gen LLM (Large Language Model) on your local machine using Ollama, a user-friendly tool for deploying LLMs.
Note: Running LLMs requires heck of hardware resources like RAM and GPU

## steps
Download Ollma

Launch Ollama: Open Ollama on your computer.

Choose an LLM Model:

Ollama offers various LLM models, including some suitable for code generation. Explore the available models within Ollama's interface. Here are some code-gen focused options to consider (subject to change and availability):

Code Llama (various sizes)

Jurassic-1 Jumbo-6B

Download the Model:

Once you've chosen your model, click the "Download" button within Ollama.

Select the appropriate quantization level (a trade-off between model size and performance) based on your available RAM.
Click "Download" again to initiate the download process.

Run Code Generation Tasks:

With the model downloaded, Ollama provides an interface for interacting with the LLM.

You can provide code-related prompts or questions, and the LLM will attempt to generate responses or complete code snippets.

The specific way to interact with the model might vary depending on Ollama's interface version.
